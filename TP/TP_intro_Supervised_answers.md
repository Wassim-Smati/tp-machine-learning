# Answers for TP Intro Supervised

In the first toy-classification part, the helper function that rounds predictions is effectively a bridge between regression and classification, since it clips and rounds continuous outputs to legal class IDs. This works as a baseline but it remains less principled than directly optimizing a classifier. Using one-hot coding for the target already improves consistency because it removes the artificial numeric ordering between class labels and lets the model select the class with the highest reconstructed response.

Across the toy scenarios, linear models such as linear regression, logistic regression, and LDA are naturally limited to linear separation. QDA, Naive Bayes in many settings, and KNN can model non-linear boundaries and therefore adapt better when class geometry is curved or locally complex. The trade-off is that flexible models may be less stable with small datasets and may require more computation. Increasing the number of samples generally improves reliability for all methods, but the gain is usually larger for methods that estimate richer decision surfaces.

In the FEI landmark exercise, shuffling is important because the original order often follows subject-level structure and may accidentally leak patterns into splits. The first feature family, based on distances to the mean configuration, is intuitive but can be weakly discriminative for subtle expressions. Preprocessing with standardization or normalization is useful because many algorithms are scale-sensitive, and preprocessing parameters must always be learned only on the training data to prevent leakage.

Cross-validation should include preprocessing inside pipelines so each fold remains independent. Without this, validation scores can be optimistic. Hyperparameter search for KNN should also be separated from final testing whenever possible. If the same data are used for tuning and reporting, estimated performance is biased upward. A held-out test set or nested cross-validation gives a better estimate of generalization.

Using all pairwise landmark distances increases feature richness but also introduces strong collinearity and redundancy. Dimensionality reduction with PCA is a practical fix and often improves stability. A manual landmark selection focused on expression-relevant regions can also work well, but errors may still occur for ambiguous faces, annotation noise, or missing cues from unselected regions. A stronger alternative is combining geometric cues from mouth, eyes, and eyebrows with localized intensity descriptors from facial patches, then evaluating the pipeline with cross-validation.
